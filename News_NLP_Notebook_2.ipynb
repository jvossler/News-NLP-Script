{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\josep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "from GoogleNews import GoogleNews\n",
    "from newspaper import Article, Config\n",
    "import nltk\n",
    "import openpyxl\n",
    "from gensim import corpora, models, matutils\n",
    "from collections import defaultdict\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk_stops = stopwords.words()\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# config will allow us to access the specified url \n",
    "# for which we are #not authorized. Sometimes we may \n",
    "# get 403 client error while parsing #the link to \n",
    "# download the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "                                               title  \\\n",
      "0  Afghanistan bar association head pleads for in...   \n",
      "1  The Taliban destroyed Afghanistan's ancient Bu...   \n",
      "2  Journalist Ahmad Baseer Ahmadi severely beaten...   \n",
      "3  More than 50 evacuees from Afghanistan in New ...   \n",
      "4  100 Days of Taliban: A chronology of events af...   \n",
      "\n",
      "                              media         date datetime  \\\n",
      "0                        Jurist.org  14 mins ago      NaT   \n",
      "1                          NBC News  17 mins ago      NaT   \n",
      "2  Committee to Protect Journalists  27 mins ago      NaT   \n",
      "3                              WHDH  47 mins ago      NaT   \n",
      "4                    Republic World  47 mins ago      NaT   \n",
      "\n",
      "                                                desc  \\\n",
      "0  The President of the Afghanistan Independent B...   \n",
      "1  The Taliban destroyed Afghanistan's Bamiyan Bu...   \n",
      "2  Washington, D.C., November 24, 2021 â€” The Tali...   \n",
      "3  More than 50 evacuees from Afghanistan have ar...   \n",
      "4  The Taliban took control of Afghanistan on Aug...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://www.jurist.org/news/2021/11/afghanista...   \n",
      "1  https://www.nbcnews.com/news/world/taliban-des...   \n",
      "2  https://cpj.org/2021/11/journalist-ahmad-basee...   \n",
      "3  https://whdh.com/news/more-than-50-evacuees-fr...   \n",
      "4  https://www.republicworld.com/world-news/rest-...   \n",
      "\n",
      "                                                 img  \n",
      "0  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
      "1  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
      "2  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
      "3  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
      "4  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "\n",
    "def web_search_function(search_term):\n",
    "    # list = []\n",
    "\n",
    "    # Set up a list of user agents to iterate through\n",
    "    user_agent_list = [\n",
    "        ('Mozilla/5.0'),  # firefox\n",
    "        ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15'),  # safari\n",
    "        ('Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0'),  # firefox\n",
    "        ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0'),  # firefox\n",
    "        ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.110 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0'),  # firefox\n",
    "        ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.89 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36'),  # chrome\n",
    "        ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'), # chrome\n",
    "        ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'), # firefox\n",
    "        ]\n",
    "\n",
    "    date_range = int(input(\"How many days do you want to go back?\"))\n",
    "\n",
    "    today = datetime.today()\n",
    "    end_date = today\n",
    "    start_date = today - timedelta(days=date_range)\n",
    "\n",
    "    end = f\"{end_date:%m/%d/%Y}\"\n",
    "    start = f\"{start_date:%m/%d/%Y}\"\n",
    "\n",
    "    # #Pick a random user agent\n",
    "    # user_agent = random.choice(user_agent_list)\n",
    "    # config = Config()\n",
    "    # config.browser_user_agent = user_agent\n",
    "    try:\n",
    "        #Pick a random user agent\n",
    "        user_agent = random.choice(user_agent_list)\n",
    "        config = Config()\n",
    "        config.browser_user_agent = user_agent\n",
    "\n",
    "        # Set up search term(s) and date range\n",
    "        # Create variables for data storage results\n",
    "        googlenews = GoogleNews(start=start, end=end, encode=\"utf-8\", period=start_date, lang=\"en\")\n",
    "        \n",
    "        # googlenews = GoogleNews(start=start, end=end)\n",
    "        # googlenews.set_lang('en')\n",
    "        # googlenews.set_encode('utf-8')\n",
    "        # googlenews.set_period(str(date_range))\n",
    "        # googlenews.set_time_range(start_date, end_date)\n",
    "\n",
    "        googlenews.search(search_term)\n",
    "\n",
    "        result = googlenews.result()\n",
    "        df = pd.DataFrame(result)\n",
    "        print(len(df))\n",
    "        print(df.head())\n",
    "        sleep(5)\n",
    "\n",
    "        # for i in range(len(df)):\n",
    "        #     googlenews.getpage(i)\n",
    "        #     result = googlenews.result()\n",
    "        #     df = pd.DataFrame(result)\n",
    "        #     sleep(2)\n",
    "\n",
    "        # if googlenews.response == 429:\n",
    "        #     #Pick a random user agent\n",
    "        #     user_agent = random.choice(user_agent_list)\n",
    "        #     config = Config()\n",
    "        #     config.browser_user_agent = user_agent\n",
    "\n",
    "        #     # Set up search term(s) and date range\n",
    "        #     # Create variables for data storage results\n",
    "        #     googlenews = GoogleNews(start='05/01/2021', end='09/11/2021')\n",
    "        #     googlenews = GoogleNews(start=start, end=end)\n",
    "        #     googlenews.search(search_term)\n",
    "        #     result = googlenews.result()\n",
    "        #     df.append(result)\n",
    "        #     print(len(df))\n",
    "        #     print(df.head())\n",
    "\n",
    "        for ind in df.index:\n",
    "            dict = {}\n",
    "\n",
    "            # Use the defined User Agent string to bypass Error: 403 codes\n",
    "            article = Article(df['link'][ind], config=config)\n",
    "\n",
    "            # Download the article return\n",
    "            article.download()\n",
    "\n",
    "            # Parse the article return\n",
    "            article.parse()\n",
    "            article.nlp()\n",
    "\n",
    "            # Create new columns in the DataFrame to store data\n",
    "            dict['Date'] = df['date'][ind]\n",
    "            dict['Media'] = df['media'][ind]\n",
    "            dict['Title'] = article.title\n",
    "            dict['Article'] = article.text\n",
    "            dict['Summary'] = article.summary\n",
    "            # Append to list\n",
    "            list.append(dict)\n",
    "            sleep(5)\n",
    "\n",
    "        # Create a new DataFrame for the appended list\n",
    "        news_df=pd.DataFrame(list)\n",
    "        # Output to excel\n",
    "        news_df.to_excel(\"articles.xlsx\")\n",
    "\n",
    "    except:\n",
    "        #Pick a random user agent\n",
    "        user_agent = random.choice(user_agent_list)\n",
    "        config = Config()\n",
    "        config.browser_user_agent(user_agent)\n",
    "\n",
    "        # Set up search term(s) and date range\n",
    "        # Create variables for data storage results\n",
    "        googlenews = GoogleNews(start='05/01/2021', end=end_date)\n",
    "        # googlenews = GoogleNews(start=start_date, end=end_date)\n",
    "        googlenews.search(search_term)\n",
    "        result = googlenews.result()\n",
    "        print(df.head())\n",
    "        print(len(df))\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            googlenews.getpage(i)\n",
    "            result = googlenews.result()\n",
    "            df = pd.DataFrame(result)\n",
    "            sleep(5)\n",
    "\n",
    "        for ind in df.index:\n",
    "            dict = {}\n",
    "\n",
    "            # Use the defined User Agent string to bypass Error: 403 codes\n",
    "            article = Article(df['link'][ind], config=config)\n",
    "\n",
    "            # Download the article return\n",
    "            article.download()\n",
    "\n",
    "            # Parse the article return\n",
    "            article.parse()\n",
    "            article.nlp()\n",
    "\n",
    "            # Create new columns in the DataFrame to store data\n",
    "            dict['Date']=df['date'][ind]\n",
    "            dict['Media']=df['media'][ind]\n",
    "            dict['Title']=article.title\n",
    "            dict['Article']=article.text\n",
    "            dict['Summary']=article.summary\n",
    "            # Append to list\n",
    "            list.append(dict)\n",
    "            sleep(5)\n",
    "\n",
    "        # Create a new DataFrame for the appended list\n",
    "        news_df=pd.DataFrame(list)\n",
    "        # Output to excel\n",
    "        news_df.to_excel(\"articles.xlsx\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # for ind in df.index:\n",
    "    #     dict = {}\n",
    "\n",
    "    #     # Use the defined User Agent string to bypass Error: 403 codes\n",
    "    #     article = Article(df['link'][ind], config=config)\n",
    "\n",
    "    #     # Download the article return\n",
    "    #     article.download()\n",
    "\n",
    "    #     # Parse the article return\n",
    "    #     article.parse()\n",
    "    #     article.nlp()\n",
    "\n",
    "    #     # Create new columns in the DataFrame to store data\n",
    "    #     dict['Date']=df['date'][ind]\n",
    "    #     dict['Media']=df['media'][ind]\n",
    "    #     dict['Title']=article.title\n",
    "    #     dict['Article']=article.text\n",
    "    #     dict['Summary']=article.summary\n",
    "    #     # Append to list\n",
    "    #     list.append(dict)\n",
    "    #     sleep(5)\n",
    "    # # Create a new DataFrame for the appended list\n",
    "    # news_df=pd.DataFrame(list)\n",
    "    # # Output to excel\n",
    "    # news_df.to_excel(\"articles.xlsx\")\n",
    "\n",
    "\n",
    "search_term = str(input(\"What term(s) do you want to search for?\"))\n",
    "web_search_function(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Notes\n",
    "### Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up a list of user agents to iterate through\n",
    "# user_agent_list = [\n",
    "#     ('Mozilla/5.0'),  # firefox\n",
    "#     ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15'),  # safari\n",
    "#     ('Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0'),  # firefox\n",
    "#     ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0'),  # firefox\n",
    "#     ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.110 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0'),  # firefox\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.89 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'), # chrome\n",
    "#     ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'), # firefox\n",
    "#     ]\n",
    "\n",
    "# today = datetime.today()\n",
    "# # today = f\"{today:%m/%d/%Y}\"\n",
    "# print(today)\n",
    "# end = today\n",
    "# start = today - timedelta(days=180)\n",
    "# end_date = f\"{end:%m/%d/%Y}\"\n",
    "# start_date = f\"{start:%m/%d/%Y}\"\n",
    "# print(start_date)\n",
    "# print(end_date)\n",
    "\n",
    "# #Pick a random user agent\n",
    "# user_agent = random.choice(user_agent_list)\n",
    "# config = Config()\n",
    "# config.browser_user_agent = user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{today:%B %d, %Y}\")\n",
    "# print(f\"{today:%m/%d/%Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up search terms and date range\n",
    "# # Create variables for data storage results\n",
    "# googlenews=GoogleNews(start=start_date,end=end_date,)\n",
    "# # googlenews.user_agent('Mozilla/5.0')\n",
    "# googlenews.search('Afghanistan'); sleep(1)\n",
    "# result=googlenews.result(); sleep(1)\n",
    "# df=pd.DataFrame(result)\n",
    "# print(df.head())\n",
    "# print(len(result))\n",
    "\n",
    "# # if googlenews.user_agent(user_agent)\n",
    "# #     print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate through Google News, get the page\n",
    "# # results, and store them in a DataFrame\n",
    "# for i in range(2,20):\n",
    "#     googlenews.getpage(i) #; sleep(2)\n",
    "#     result = googlenews.result()\n",
    "#     df=pd.DataFrame(result)\n",
    "#     sleep(1)\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "382911a3b25c08601c92d532ecf77b76535fbec3aff100266cbea416b7e83b72"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
